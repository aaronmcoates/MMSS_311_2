---
title: "HW2 Num2"
author: "Aaron Coates"
date: "5/4/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

2.1 (a.)
```{r}
setwd("~/Documents/GitHub/MMSS_311_2")

TwitterData <- read.csv('/Users/aaroncoates/Downloads/trumptweets.csv')

library(tidytext)
library(tm)
library(dplyr)
library(broom)
library(lubridate)
library(stringr)
library(ggplot2)
library(tidyr)
```

2.1 (b.)
```{r}
tweetcorpus <- Corpus(VectorSource(as.vector(TwitterData$text)))

processedcorpus <- tweetcorpus %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(content_transformer(stemDocument), language = "english") %>%
  tm_map(content_transformer(removePunctuation))
```

2.1 (c.)
```{r}
DTMatrix <- DocumentTermMatrix(processedcorpus)
SparseDTMatrix <- removeSparseTerms(DTMatrix, .99)
inspect(SparseDTMatrix[1:10,1:10])
```

2.1 (d.)
```{r}
tidymatrix <- tidy(DTMatrix)
```

2.1 (e.)
```{r}
TfIdfMat <- DocumentTermMatrix(processedcorpus, control
                          = list(weighting = weightTfIdf))
SparseTfIdfMat <- removeSparseTerms(TfIdfMat, .99)
inspect(SparseTfIdfMat[1:10,1:10])
```

2.2 (a.)
```{r}
popterms <- tidymatrix %>%
  group_by(term) %>%
  summarize(frequency = sum(count)) %>%
  arrange(desc(frequency))
popterms[1:20,1:2]
```

2.2 (b.) Post-Election
```{r}
TwitterDataDate <- TwitterData
TwitterDataDate$date <- as.Date(TwitterData$created_at, '%m-%d-%Y')

PostTwitterData <- subset(TwitterDataDate, date >= as.Date('2016-11-08'))
PreTwitterData <- subset(TwitterDataDate, date <= as.Date('2016-11-08'))

posttweetcorpus <- Corpus(VectorSource(as.vector(PostTwitterData$text)))

postprocessedcorpus <- posttweetcorpus %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(content_transformer(stemDocument), language = "english") %>%
  tm_map(content_transformer(removePunctuation))

postDTMatrix <- DocumentTermMatrix(postprocessedcorpus)
postSparseDTMatrix <- removeSparseTerms(postDTMatrix, .99)
posttidymatrix <- tidy(postDTMatrix)

postpopterms <- posttidymatrix %>%
  group_by(term) %>%
  summarize(frequency = sum(count)) %>%
  arrange(desc(frequency))
postpopterms[1:20,1:2]
```

2.2 (b.) Pre-Election
```{r}
pretweetcorpus <- Corpus(VectorSource(as.vector(PreTwitterData$text)))

preprocessedcorpus <- pretweetcorpus %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(content_transformer(stemDocument), language = "english") %>%
  tm_map(content_transformer(removePunctuation))

preDTMatrix <- DocumentTermMatrix(preprocessedcorpus)
preSparseDTMatrix <- removeSparseTerms(preDTMatrix, .99)
inspect(preSparseDTMatrix[1:10,1:10])
pretidymatrix <- tidy(preDTMatrix)

prepopterms <- pretidymatrix %>%
  group_by(term) %>%
  summarize(frequency = sum(count)) %>%
  arrange(desc(frequency))
prepopterms[1:20,1:2]
```
For Pre-Election, we see many campaign related words, such as "Obama" and "Make America great", which was part of Trump's slogan, "Make America great again." For Post-Election, we see many of Trump's focuses while in the presidency, such as "fake news", "taxes", and "jobs."

2.2 (c.)
```{r}
hashtagcorpus <- Corpus(VectorSource(as.vector(TwitterData$text)))

hashtag <- function(x) gsub("[^#[:alnum:][:space:]]", "", x)
htcorpus2 <- tm_map(hashtagcorpus, content_transformer(hashtag)) %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(content_transformer(tolower))

htDTMatrix <- DocumentTermMatrix(htcorpus2)
tidyhash <- tidy(htDTMatrix)
```

2.2 (d.)
```{r}
popht <- tidyhash %>%
  group_by(term) %>%
  summarize(frequency = sum(count)) %>%
  arrange(desc(frequency))

hashtagdaddy <- subset(popht, grepl("#", term))
hashtagdaddy[1:5, 1:2]
```

2.2 (e.)
```{r}
DateHashtag <- tidyhash %>%
  subset(term == '#maga' | term == '#trump2016'
         | term == '#celebapprentice' | term == '#celebrityapprentice'
         | term == '#makeamericagreatagain')

x <- 1:17200
TwitterData$document <- x
TwitterData$document <- as.character(TwitterData$document)

final <- inner_join(DateHashtag, TwitterData, by = 'document')
final <- final[, c('document', 'term', 'created_at', 'count')]

final$date <- as.Date(final$created_at, '%m-%d-%Y')
final$month <- format(final$date, '%Y-%m')

maga <- final %>%
  group_by(month, term) %>%
  summarise(frequency = sum(count))

maga <- arrange(maga, month)
```

```{r, echo=FALSE, fig.width=8}
ggplot(data=maga, aes(x=month, y=frequency, group = term, colour = term)) +
  geom_line() +
  geom_point(size=4, shape=21, fill="white") + coord_flip()
```

2.2 (f.)
```{r}
Crooked <- TwitterData
Crooked <- select(Crooked, c(text, created_at)) %>%
  unnest_tokens(bigram, text, token='ngrams', n=2)
Crooked$date <- as.Date(Crooked$created_at, '%m-%d-%Y')
Crooked$month <- format(Crooked$date, '%Y-%m')

Crooked <- subset(Crooked, bigram=='crooked hillary')

for (i in 1:nrow(Crooked)) {
  Crooked$count[i] =1
}

finalcrooked <- Crooked %>%
  group_by(month) %>%
  summarise(frequency = sum(count))
```

```{r, echo=FALSE, fig.width=4}
ggplot(data=finalcrooked, aes(x=month, y=frequency)) +
  geom_col(color='blue', fill='red') 
```


