anti_join(stop_words) %>%
mutate(word = removeNumbers(word)) %>%
mutate(word = stripWhitespace(word)) %>%
mutate(word = removePunctuation(word)) %>%
mutate(word = stemDocument(word)) %>%
group_by(doc_id) %>%
count(word) %>%
subset(word != '') %>%
cast_dtm(doc_id, word, n) %>%
removeSparseTerms(0.99) %>%
as.matrix()
eucdist.mani <- dist(tidymani) %>%
as.matrix()
eucdist.mani
manifestosabc <- manifestos[order(manifestos$doc_id),]
image.plot(1:ncol(eucdist.mani), 1:ncol(eucdist.mani), eucdist.mani, axes=F, xlab="Party", ylab="Party")
axis(1, 1:ncol(eucdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
axis(2, 1:ncol(eucdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
cosdist.mani <- dist(tidymani, method="cosine") %>%
as.matrix()
cosdist.mani
image.plot(1:ncol(cosdist.mani), 1:ncol(cosdist.mani), cosdist.mani, axes=F, xlab="Party", ylab="Party")
axis(1, 1:ncol(cosdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
axis(2, 1:ncol(cosdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
knitr::opts_chunk$set(echo = TRUE)
cosdist.mani <- dist(tidymani, method="cosine") %>%
as.matrix()
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/MMSS_311_2")
library(tidytext)
library(tm)
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(proxy)
library(fields)
library(mixtools)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
tidymani <- manifestos %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
mutate(word = removeNumbers(word)) %>%
mutate(word = stripWhitespace(word)) %>%
mutate(word = removePunctuation(word)) %>%
mutate(word = stemDocument(word)) %>%
group_by(doc_id) %>%
count(word) %>%
subset(word != '') %>%
cast_dtm(doc_id, word, n) %>%
removeSparseTerms(0.99) %>%
as.matrix()
eucdist.mani <- dist(tidymani) %>%
as.matrix()
eucdist.mani
manifestosabc <- manifestos[order(manifestos$doc_id),]
image.plot(1:ncol(eucdist.mani), 1:ncol(eucdist.mani), eucdist.mani, axes=F, xlab="Party", ylab="Party")
axis(1, 1:ncol(eucdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
axis(2, 1:ncol(eucdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
cosdist.mani <- dist(tidymani, method="cosine") %>%
as.matrix()
cosdist.mani
image.plot(1:ncol(cosdist.mani), 1:ncol(cosdist.mani), cosdist.mani, axes=F, xlab="Party", ylab="Party")
axis(1, 1:ncol(cosdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
axis(2, 1:ncol(cosdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
knitr::opts_chunk$set(echo = TRUE)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
setwd("~/Documents/GitHub/MMSS_311_2")
library(tidytext)
library(tm)
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(proxy)
library(fields)
library(mixtools)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
knitr::opts_chunk$set(echo = TRUE)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/MMSS_311_2")
library(tidytext)
library(tm)
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(proxy)
library(fields)
library(mixtools)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
tidymani <- manifestos %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
mutate(word = removeNumbers(word)) %>%
mutate(word = stripWhitespace(word)) %>%
mutate(word = removePunctuation(word)) %>%
mutate(word = stemDocument(word)) %>%
group_by(doc_id) %>%
count(word) %>%
subset(word != '') %>%
cast_dtm(doc_id, word, n) %>%
removeSparseTerms(0.99) %>%
as.matrix()
View(tidymani)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
tidymani <- manifestos %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
mutate(word = removeNumbers(word)) %>%
mutate(word = stripWhitespace(word)) %>%
mutate(word = removePunctuation(word)) %>%
mutate(word = stemDocument(word)) %>%
group_by(doc_id) %>%
count(word) %>%
subset(word != '') %>%
cast_dtm(doc_id, word, n) %>%
removeSparseTerms(0.99) %>%
as.matrix() %>%
tidy()
View(tidymani)
manifestos[1,2]
View(manifestos)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/MMSS_311_2")
library(tidytext)
library(tm)
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(proxy)
library(fields)
library(mixtools)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
tidymani <- manifestos %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
mutate(word = removeNumbers(word)) %>%
mutate(word = stripWhitespace(word)) %>%
mutate(word = removePunctuation(word)) %>%
mutate(word = stemDocument(word)) %>%
group_by(doc_id) %>%
count(word) %>%
subset(word != '') %>%
cast_dtm(doc_id, word, n) %>%
removeSparseTerms(0.99) %>%
as.matrix()
eucdist.mani <- dist(tidymani) %>%
as.matrix()
eucdist.mani
manifestosabc <- manifestos[order(manifestos$doc_id),]
View(tidymani)
corpus <- VCorpus(DataframeSource(manifestos))
corpus <- corpus %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeWords, stopwords('english')) %>%
tm_map(stemDocument) %>%
tm_map(stripWhitespace)
dtm <- DocumentTermMatrix(corpus)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- DocumentTermMatrix(corpus)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix() %>%
tidy()
View(dtm)
corpus <- corpus %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeWords, stopwords('english')) %>%
tm_map(stemDocument) %>%
tm_map(stripWhitespace)
corpus <- VCorpus(DataframeSource(manifestos))
corpus <- corpus %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeWords, stopwords('english')) %>%
tm_map(stemDocument) %>%
tm_map(stripWhitespace)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeWords, stopwords('english')) %>%
tm_map(stemDocument) %>%
tm_map(stripWhitespace)
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix() %>%
tidy()
View(dtm)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english") %>%
tm_map(content_transformer(removePunctuation))
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix() %>%
tidy()
View(dtm)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(removePunctuation)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix() %>%
tidy()
View(dtm)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(content_transformer(removePunctuation)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix() %>%
tidy()
View(dtm)
inspect(manifestos[1, 2])
manifestos[1,2]
manifestos[2,2]
manifestos2 <- read.csv("/Users/aaroncoates/Downloads/manifestos.csv")
manifestos[2,2]
View(manifestos2)
manifestos[2,2]
manifestos2[2,2]
View(dtm)
View(dtm)
View(dtm)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(content_transformer(removePunctuation)) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix()
View(dtm)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix()
View(dtm)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation(preserve_intra_word_contractions = FALSE, preserve_intra_word_dashes = FALSE,
ucp = FALSE)) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation(preserve_intra_word_contractions = FALSE, preserve_intra_word_dashes = FALSE)) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix()
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation(corpus3, preserve_intra_word_contractions = FALSE, preserve_intra_word_dashes = FALSE)) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix()
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation, preserve_intra_word_contractions = FALSE, preserve_intra_word_dashes = FALSE) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix()
View(dtm)
removeSpecialChars <- function(x) gsub("[^a-zA-Z0-9 ]","",x)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation, preserve_intra_word_contractions = FALSE, preserve_intra_word_dashes = FALSE) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english") %>%
tm_map(removeSpecialChars)
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix()
removeSpecialChars <- function(x) gsub("[^a-zA-Z0-9 ]","",x)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english") %>%
tm_map(removeSpecialChars)
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix()
removeSpecialChars <- function(x) gsub("[^a-zA-Z0-9 ]","",x)
setwd("~/Documents/GitHub/MMSS_311_2")
library(tidytext)
library(tm)
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(proxy)
library(fields)
library(mixtools)
library(topicmodels)
library(stm)
set.seed(732)
Ari <- read_csv("/Users/aaroncoates/Downloads/tx_deathrow_full.csv")
Ari <- Ari[is.na(Ari$'Last Statement')!=1, ]
removeSpecialChars <- function(x) gsub("[^a-zA-Z0-9 ]","",x)
Taylor <- Ari %>%
unnest_tokens(word, 'Last Statement') %>%
anti_join(stop_words) %>%
group_by(Execution) %>%
removePunctuation() %>%
count(word) %>%
cast_dtm(Execution, word, n) %>%
as.matrix()
Britney <- LDA(Taylor, k=10)
Kelly <- Britney %>%
tidy() %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup()
CarlyRae <- ggplot(Kelly, aes(term, beta, fill= as.factor(topic))) +
facet_wrap(~ topic, scales= 'free_y', nrow = 2) + coord_flip() +
geom_col(show.legend = FALSE) + xlab('Term') + ylab('Beta') +
labs(title="Topic Modeling of Death Row Final Statements, LDA", subtitle="Top 10 Words Per Topic")
CarlyRae
Beyonce <- stm::readCorpus(Taylor, type = 'dtm')
Normani <- as.data.frame(Taylor)
Normani$ExecutionNumber <- as.numeric(rownames(Normani))
Camila <- semi_join(Ari, Normani, by = c('Execution' = 'ExecutionNumber'))
Adele <- stm(documents = Beyonce$documents, vocab = Beyonce$vocab,
K = 10, prevalence = ~ Race, data = Camila)
labelTopics(Adele)
plot.STM(Adele, type = "summary", n=5, xlim=c(0,1))
summary(Adele)
Miley <- tidy(Adele) %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup()
Demi <- ggplot(Miley, aes(term, beta, fill= as.factor(topic))) +
facet_wrap(~ topic, scales= 'free_y', nrow = 2) + coord_flip() +
geom_col(show.legend = FALSE) + xlab('Term') + ylab('Beta') +
labs(title="Topic Modeling of Death Row Final Statements, STM", subtitle="Top 10 Words Per Topic")
Demi
setwd("~/Documents/GitHub/MMSS_311_2")
library(tidytext)
library(tm)
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(proxy)
library(fields)
library(mixtools)
library(topicmodels)
library(stm)
set.seed(732)
Ari <- read_csv("/Users/aaroncoates/Downloads/tx_deathrow_full.csv")
Ari <- Ari[is.na(Ari$'Last Statement')!=1, ]
removeSpecialChars <- function(x) gsub("[^a-zA-Z0-9 ]","",x)
Taylor <- Ari %>%
unnest_tokens(word, 'Last Statement') %>%
anti_join(stop_words) %>%
group_by(Execution) %>%
removePunctuation() %>%
count(word) %>%
cast_dtm(Execution, word, n) %>%
as.matrix()
Britney <- LDA(Taylor, k=10)
Kelly <- Britney %>%
tidy() %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup()
CarlyRae <- ggplot(Kelly, aes(term, beta, fill= as.factor(topic))) +
facet_wrap(~ topic, scales= 'free_y', nrow = 2) + coord_flip() +
geom_col(show.legend = FALSE) + xlab('Term') + ylab('Beta') +
labs(title="Topic Modeling of Death Row Final Statements, LDA", subtitle="Top 10 Words Per Topic")
CarlyRae
Beyonce <- stm::readCorpus(Taylor, type = 'dtm')
Normani <- as.data.frame(Taylor)
Normani$ExecutionNumber <- as.numeric(rownames(Normani))
Camila <- semi_join(Ari, Normani, by = c('Execution' = 'ExecutionNumber'))
Adele <- stm(documents = Beyonce$documents, vocab = Beyonce$vocab,
K = 10, prevalence = ~ Race, data = Camila)
labelTopics(Adele)
plot.STM(Adele, type = "summary", n=5, xlim=c(0,1))
summary(Adele)
Miley <- tidy(Adele) %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup()
Demi <- ggplot(Miley, aes(term, beta, fill= as.factor(topic))) +
facet_wrap(~ topic, scales= 'free_y', nrow = 2) + coord_flip() +
geom_col(show.legend = FALSE) + xlab('Term') + ylab('Beta') +
labs(title="Topic Modeling of Death Row Final Statements, STM", subtitle="Top 10 Words Per Topic")
Demi
setwd("~/Documents/GitHub/MMSS_311_2")
library(tidytext)
library(tm)
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(proxy)
library(fields)
library(mixtools)
library(topicmodels)
library(stm)
set.seed(732)
Ari <- read_csv("/Users/aaroncoates/Downloads/tx_deathrow_full.csv")
Ari <- Ari[is.na(Ari$'Last Statement')!=1, ]
Taylor <- Ari %>%
unnest_tokens(word, 'Last Statement') %>%
anti_join(stop_words) %>%
removePunctuation() %>%
group_by(Execution) %>%
count(word) %>%
cast_dtm(Execution, word, n) %>%
as.matrix()
Taylor <- Ari %>%
unnest_tokens(word, 'Last Statement') %>%
anti_join(stop_words) %>%
removePunctuation()
Taylor <- Ari %>%
unnest_tokens(word, 'Last Statement') %>%
anti_join(stop_words) %>%
mutate(word = removePunctuation(word)) %>%
group_by(Execution) %>%
count(word) %>%
cast_dtm(Execution, word, n) %>%
as.matrix()
Britney <- LDA(Taylor, k=10)
Kelly <- Britney %>%
tidy() %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup()
CarlyRae <- ggplot(Kelly, aes(term, beta, fill= as.factor(topic))) +
facet_wrap(~ topic, scales= 'free_y', nrow = 2) + coord_flip() +
geom_col(show.legend = FALSE) + xlab('Term') + ylab('Beta') +
labs(title="Topic Modeling of Death Row Final Statements, LDA", subtitle="Top 10 Words Per Topic")
CarlyRae
Beyonce <- stm::readCorpus(Taylor, type = 'dtm')
Normani <- as.data.frame(Taylor)
Normani$ExecutionNumber <- as.numeric(rownames(Normani))
Camila <- semi_join(Ari, Normani, by = c('Execution' = 'ExecutionNumber'))
Adele <- stm(documents = Beyonce$documents, vocab = Beyonce$vocab,
K = 10, prevalence = ~ Race, data = Camila)
labelTopics(Adele)
plot.STM(Adele, type = "summary", n=5, xlim=c(0,1))
summary(Adele)
Miley <- tidy(Adele) %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup()
Demi <- ggplot(Miley, aes(term, beta, fill= as.factor(topic))) +
facet_wrap(~ topic, scales= 'free_y', nrow = 2) + coord_flip() +
geom_col(show.legend = FALSE) + xlab('Term') + ylab('Beta') +
labs(title="Topic Modeling of Death Row Final Statements, STM", subtitle="Top 10 Words Per Topic")
Demi
