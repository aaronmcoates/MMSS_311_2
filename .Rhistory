plot(crossvallasso)
crossvallasso$lambda.min
coef(crossvallasso, s = "lambda.min")
knitr::opts_chunk$set(echo = TRUE)
naive <- naiveBayes(group ~ pol_margin + col_degree + house_income, data=trainingdata)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/MMSS_311_2")
pol <- read.csv("/Users/aaroncoates/Downloads/pol_data.csv")
library(broom)
library(e1071)
library(caret)
pol$group <- as.factor(pol$group)
trainsize <- floor((2/3)*nrow(pol))
set.seed(100)
train_pol <- sample(nrow(pol), size = trainsize, replace=FALSE)
trainingdata <- pol[train_pol, ]
testydata <- pol[-train_pol, ]
tunez <- tune(svm, group ~ pol_margin + col_degree + house_income,
data=trainingdata, kernel = "linear",
ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
swaggysvm <- tunez$best.model
summary(swaggysvm)
svmpredict <- predict(swaggysvm, testydata)
svmtable <- table("Prediction"=svmpredict, "True Party"=testydata[,1])
svmtable
naive <- naiveBayes(group ~ pol_margin + col_degree + house_income, data=trainingdata)
naivetidy <- tidy(naive)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/MMSS_311_2")
pol <- read.csv("/Users/aaroncoates/Downloads/pol_data.csv")
library(broom)
library(e1071)
library(caret)
pol$group <- as.factor(pol$group)
trainsize <- floor((2/3)*nrow(pol))
set.seed(100)
train_pol <- sample(nrow(pol), size = trainsize, replace=FALSE)
trainingdata <- pol[train_pol, ]
testydata <- pol[-train_pol, ]
tunez <- tune(svm, group ~ pol_margin + col_degree + house_income,
data=trainingdata, kernel = "linear",
ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
swaggysvm <- tunez$best.model
summary(swaggysvm)
svmpredict <- predict(swaggysvm, testydata)
svmtable <- table("Prediction"=svmpredict, "True Party"=testydata[,1])
svmtable
naive <- naiveBayes(group ~ pol_margin + col_degree + house_income, data=trainingdata)
naivepred <- predict(naive, testydata)
naivetable <- table("Prediction"=naivepred, "True Party"=testydata[,1])
naivetable
View(naive)
View(naive)
read.csv("/Users/aaroncoates/Downloads/reports.csv")
CSV <- read.csv("/Users/aaroncoates/Downloads/reports.csv")
View(CSV)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/MMSS_311_2")
TwitterData <- read.csv('/Users/aaroncoates/Downloads/trumptweets.csv')
library(tidytext)
library(tm)
library(dplyr)
library(broom)
library(lubridate)
library(stringr)
library(ggplot2)
library(tidyr)
View(TwitterData)
CSV <- read.csv("/Users/aaroncoates/Downloads/CPDS-1960-2016-Update-2018.xlsx")
CSV <- read.csv("/Users/aaroncoates/Downloads/CPDS-1960-2016-Update-2018.xlsx")
CSV <- read.csv("/Users/aaroncoates/Downloads/500_Cities__City-level_Data__GIS_Friendly_Format___2018_release.csv")
View(CSV)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/MMSS_311_2")
library(tidytext)
library(tm)
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(proxy)
library(fields)
library(mixtools)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
tidymani <- manifestos %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
mutate(word = removeNumbers(word)) %>%
mutate(word = stripWhitespace(word)) %>%
mutate(word = removePunctuation(word)) %>%
mutate(word = stemDocument(word)) %>%
group_by(doc_id) %>%
count(word) %>%
subset(word != '') %>%
cast_dtm(doc_id, word, n) %>%
removeSparseTerms(0.99) %>%
as.matrix()
eucdist.mani <- dist(tidymani) %>%
as.matrix()
eucdist.mani
manifestosabc <- manifestos[order(manifestos$doc_id),]
image.plot(1:ncol(eucdist.mani), 1:ncol(eucdist.mani), eucdist.mani, axes=F, xlab="Party", ylab="Party")
axis(1, 1:ncol(eucdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
axis(2, 1:ncol(eucdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
cosdist.mani <- dist(tidymani, method="cosine") %>%
as.matrix()
cosdist.mani
image.plot(1:ncol(cosdist.mani), 1:ncol(cosdist.mani), cosdist.mani, axes=F, xlab="Party", ylab="Party")
axis(1, 1:ncol(cosdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
axis(2, 1:ncol(cosdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/MMSS_311_2")
library(tidytext)
library(tm)
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(proxy)
library(fields)
library(mixtools)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
tidymani <- manifestos %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
mutate(word = removeNumbers(word)) %>%
mutate(word = stripWhitespace(word)) %>%
mutate(word = removePunctuation(word)) %>%
mutate(word = stemDocument(word)) %>%
group_by(doc_id) %>%
count(word) %>%
subset(word != '') %>%
cast_dtm(doc_id, word, n) %>%
removeSparseTerms(0.99) %>%
as.matrix()
eucdist.mani <- dist(tidymani) %>%
as.matrix()
eucdist.mani
manifestosabc <- manifestos[order(manifestos$doc_id),]
image.plot(1:ncol(eucdist.mani), 1:ncol(eucdist.mani), eucdist.mani, axes=F, xlab="Party", ylab="Party")
axis(1, 1:ncol(eucdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
axis(2, 1:ncol(eucdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
cosdist.mani <- dist(tidymani, method="cosine") %>%
as.matrix()
cosdist.mani
image.plot(1:ncol(cosdist.mani), 1:ncol(cosdist.mani), cosdist.mani, axes=F, xlab="Party", ylab="Party")
axis(1, 1:ncol(cosdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
axis(2, 1:ncol(cosdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
knitr::opts_chunk$set(echo = TRUE)
cosdist.mani <- dist(tidymani, method="cosine") %>%
as.matrix()
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/MMSS_311_2")
library(tidytext)
library(tm)
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(proxy)
library(fields)
library(mixtools)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
tidymani <- manifestos %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
mutate(word = removeNumbers(word)) %>%
mutate(word = stripWhitespace(word)) %>%
mutate(word = removePunctuation(word)) %>%
mutate(word = stemDocument(word)) %>%
group_by(doc_id) %>%
count(word) %>%
subset(word != '') %>%
cast_dtm(doc_id, word, n) %>%
removeSparseTerms(0.99) %>%
as.matrix()
eucdist.mani <- dist(tidymani) %>%
as.matrix()
eucdist.mani
manifestosabc <- manifestos[order(manifestos$doc_id),]
image.plot(1:ncol(eucdist.mani), 1:ncol(eucdist.mani), eucdist.mani, axes=F, xlab="Party", ylab="Party")
axis(1, 1:ncol(eucdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
axis(2, 1:ncol(eucdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
cosdist.mani <- dist(tidymani, method="cosine") %>%
as.matrix()
cosdist.mani
image.plot(1:ncol(cosdist.mani), 1:ncol(cosdist.mani), cosdist.mani, axes=F, xlab="Party", ylab="Party")
axis(1, 1:ncol(cosdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
axis(2, 1:ncol(cosdist.mani), manifestosabc$doc_id, cex.axis=.7, las=2)
knitr::opts_chunk$set(echo = TRUE)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
setwd("~/Documents/GitHub/MMSS_311_2")
library(tidytext)
library(tm)
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(proxy)
library(fields)
library(mixtools)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
knitr::opts_chunk$set(echo = TRUE)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/MMSS_311_2")
library(tidytext)
library(tm)
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(proxy)
library(fields)
library(mixtools)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
tidymani <- manifestos %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
mutate(word = removeNumbers(word)) %>%
mutate(word = stripWhitespace(word)) %>%
mutate(word = removePunctuation(word)) %>%
mutate(word = stemDocument(word)) %>%
group_by(doc_id) %>%
count(word) %>%
subset(word != '') %>%
cast_dtm(doc_id, word, n) %>%
removeSparseTerms(0.99) %>%
as.matrix()
View(tidymani)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
tidymani <- manifestos %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
mutate(word = removeNumbers(word)) %>%
mutate(word = stripWhitespace(word)) %>%
mutate(word = removePunctuation(word)) %>%
mutate(word = stemDocument(word)) %>%
group_by(doc_id) %>%
count(word) %>%
subset(word != '') %>%
cast_dtm(doc_id, word, n) %>%
removeSparseTerms(0.99) %>%
as.matrix() %>%
tidy()
View(tidymani)
manifestos[1,2]
View(manifestos)
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/MMSS_311_2")
library(tidytext)
library(tm)
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(proxy)
library(fields)
library(mixtools)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
tidymani <- manifestos %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
mutate(word = removeNumbers(word)) %>%
mutate(word = stripWhitespace(word)) %>%
mutate(word = removePunctuation(word)) %>%
mutate(word = stemDocument(word)) %>%
group_by(doc_id) %>%
count(word) %>%
subset(word != '') %>%
cast_dtm(doc_id, word, n) %>%
removeSparseTerms(0.99) %>%
as.matrix()
eucdist.mani <- dist(tidymani) %>%
as.matrix()
eucdist.mani
manifestosabc <- manifestos[order(manifestos$doc_id),]
View(tidymani)
corpus <- VCorpus(DataframeSource(manifestos))
corpus <- corpus %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeWords, stopwords('english')) %>%
tm_map(stemDocument) %>%
tm_map(stripWhitespace)
dtm <- DocumentTermMatrix(corpus)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- DocumentTermMatrix(corpus)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix() %>%
tidy()
View(dtm)
corpus <- corpus %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeWords, stopwords('english')) %>%
tm_map(stemDocument) %>%
tm_map(stripWhitespace)
corpus <- VCorpus(DataframeSource(manifestos))
corpus <- corpus %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeWords, stopwords('english')) %>%
tm_map(stemDocument) %>%
tm_map(stripWhitespace)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removeWords, stopwords('english')) %>%
tm_map(stemDocument) %>%
tm_map(stripWhitespace)
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix() %>%
tidy()
View(dtm)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english") %>%
tm_map(content_transformer(removePunctuation))
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix() %>%
tidy()
View(dtm)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(removePunctuation)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix() %>%
tidy()
View(dtm)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(content_transformer(removePunctuation)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix() %>%
tidy()
View(dtm)
inspect(manifestos[1, 2])
manifestos[1,2]
manifestos[2,2]
manifestos2 <- read.csv("/Users/aaroncoates/Downloads/manifestos.csv")
manifestos[2,2]
View(manifestos2)
manifestos[2,2]
manifestos2[2,2]
View(dtm)
View(dtm)
View(dtm)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(content_transformer(removePunctuation)) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix()
View(dtm)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix()
View(dtm)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation(preserve_intra_word_contractions = FALSE, preserve_intra_word_dashes = FALSE,
ucp = FALSE)) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation(preserve_intra_word_contractions = FALSE, preserve_intra_word_dashes = FALSE)) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix()
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation(corpus3, preserve_intra_word_contractions = FALSE, preserve_intra_word_dashes = FALSE)) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix()
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation, preserve_intra_word_contractions = FALSE, preserve_intra_word_dashes = FALSE) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix()
View(dtm)
removeSpecialChars <- function(x) gsub("[^a-zA-Z0-9 ]","",x)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation, preserve_intra_word_contractions = FALSE, preserve_intra_word_dashes = FALSE) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english") %>%
tm_map(removeSpecialChars)
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix()
removeSpecialChars <- function(x) gsub("[^a-zA-Z0-9 ]","",x)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english") %>%
tm_map(removeSpecialChars)
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix()
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation) %>%
tm_map(content_transformer(removeSpecialChars)) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english")
setwd("~/Documents/GitHub/MMSS_311_2")
library(tidytext)
library(tm)
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(proxy)
library(fields)
library(mixtools)
manifestos <- read_csv("/Users/aaroncoates/Downloads/manifestos.csv")
removeSpecialChars <- function(x) gsub("[^a-zA-Z0-9 ]","",x)
corpus3 <- VCorpus(DataframeSource(manifestos))
corpus4 <- corpus3 %>%
tm_map(removePunctuation) %>%
tm_map(content_transformer(removeSpecialChars)) %>%
tm_map(content_transformer(removeNumbers)) %>%
tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(stemDocument), language = "english")
dtm <- DocumentTermMatrix(corpus4)
dtm <- removeSparseTerms(dtm, 0.97)
dtm <- dtm %>%
as.matrix()
View(dtm)
tidymani <- manifestos %>%
unnest_tokens(word, text) %>%
anti_join(stop_words) %>%
mutate(word = removeNumbers(word)) %>%
mutate(word = stripWhitespace(word)) %>%
mutate(word = removePunctuation(word)) %>%
mutate(word = stemDocument(word)) %>%
group_by(doc_id) %>%
count(word) %>%
subset(word != '') %>%
cast_dtm(doc_id, word, n) %>%
removeSparseTerms(0.99) %>%
as.matrix()
View(tidymani)
